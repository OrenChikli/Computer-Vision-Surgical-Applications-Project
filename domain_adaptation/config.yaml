# Phase 3: Domain Adaptation Configuration
# EXAMPLE CONFIGURATION - Update these paths for your setup
# For portable configuration, copy config_example.yaml and customize

# Input paths - UPDATE THESE FOR YOUR SETUP
paths:
  # Path to your trained Phase 2 model (from YOLO training results)
  model_path:  "D:/Vision_project_data/yolo_runs/train11/weights/best.pt" #"../training_results/surgical_pose_v1/weights/best.pt"
  
  # Path to your Phase 1 synthetic dataset (YOLO format)
  synthetic_data_path: "D:/Vision_project_data/datasets/dataset_1920_new/yolo_dataset" #"../datasets/yolo_dataset"
  
  # Path to real surgical video for domain adaptation  
  real_video_path: "C:/Users/fchik/OneDrive/Study/Technion/2025b/vision/Project/data/vids_tune/4_2_24_B_2.mp4" #"../data/real_videos/surgical_video.mp4"
  
  # Output directory for domain adaptation results
  output_dir: "D:/Vision_project_data/domain_adaptation/dataset_1920_new_final_code" #"../output/domain_adaptation_results"

video_annotation:
  enabled: true  # Set to false to skip video creation (faster)
  confidence_threshold: 0.5  # Confidence threshold for video annotations
  save_format: "mp4"  # Video format
  progress_logging: true  # Log progress during video creation

# Pseudo-labeling parameters
pseudo_labeling:
  confidence_threshold: 0.8      # Minimum confidence for pseudo-labels
  track_min_length: 3           # Minimum track length for stability
  max_pseudo_labels: 500       # Maximum number of pseudo-labels to prevent imbalance

# Iterative refinement parameters
refinement:
  iterations: 3                 # Number of refinement iterations (1 = single pass, 2+ = iterative)
  save_intermediate_models: true # Save model after each iteration
  accumulate_data: True        # Whether to accumulate data from previous iterations

# Tracking parameters
tracking:
  tracker: "botsort.yaml"       # Tracker configuration
  persist: true                 # Maintain tracks across frames
  verbose: false               # Reduce tracking output

# Training parameters
training:
  epochs: 10                  # Number of training epochs
  batch_size: 16              # Batch size for training
  imgsz: 640                  # Image size for training
  device: "auto"              # Device selection (auto/cpu/cuda)
  verbose: true               # Training verbosity

# Model parameters
model:
  pretrained: true            # Use pretrained weights
  exist_ok: true             # Allow existing project directories

# Evaluation parameters
evaluation:
  run_evaluation: true        # Whether to run automatic evaluation after domain adaptation
  sample_rate: 5             # Process every nth frame during evaluation (1 = every frame)

# Data processing
data:
  image_extensions: [".jpg", ".jpeg", ".png", ".bmp"]
  label_extension: ".txt"

# Output structure
output:
  images_dir: "images"
  labels_dir: "labels"
  pseudo_dir: "pseudo_labeled"
  dataset_config: "dataset.yaml"
  refined_model_dir: "refined_model"

# Logging
logging:
  level: "INFO"              # DEBUG, INFO, WARNING, ERROR
  format: "%(asctime)s - %(name)s - %(levelname)s - %(message)s"

memory_management:
  chunk_size: 50
  cleanup_frequency: 100
  force_cpu_inference: false
  max_frames_in_memory: 200